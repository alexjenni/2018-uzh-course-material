{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Project\n",
    "\n",
    "In this part of the course we will use Python to predict polls as outcomes of the 2016 Prsidential Election. Sound's fun? \n",
    "\n",
    "Here's what we're going to do:\n",
    "1. use selenium to scrape search volume data from Google Trends\n",
    "3. use pandas to prepare the data\n",
    "2. use data.world to download 538 data from polls in each state\n",
    "4. use scipy to do some data analysis\n",
    "5. use XXX to visualize our results\n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Web scraping\n",
    "Before starting to code your brains out, it's worth taking a look at [Google Trends](https://trends.google.com/trends). Familiarize yourself with the basic functionalities of the website. Search for something and try to get the data in csv form.\n",
    "\n",
    "Some things to think about:\n",
    "- Google Trends normalizes the data so that the peak search interest in the results corresponds to a value of 100. You can't unnormalize the data, but maybe it can actually save you time! Ask: How would I normalize anyways?\n",
    "- With this in mind, should you search for both candidates simultaneously or for one at a time?\n",
    "- There are different options to search: search terms and concepts. Which should you use?\n",
    "- We want to have a time series for each state. There two main ways to accomplish this: export the time series for each state or export the data in the map for each time point. Which should you use?\n",
    "- can you use a static method or will you have to used a dynamic webdriver?\n",
    "\n",
    "For this step-by-step guide we will compare both search terms simultaneously and export the map data for every day in the year leading up to the election. If the volume is very low, Google doesn't report anything. Although there exists a [workaround](https://www.sciencedirect.com/science/article/pii/S0047272714000929) we won't bother with it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, write write a function `open_driver()` that imports and opens the selenium webdriver. Return the webdriver as an object. I suggest that you also import `By` and `Options`. \n",
    "\n",
    "You could try changing the download location using Options, but it might not work on your OS. We'll rename the downloads anyways so you can just move them to the correct location at that step. Don't worry, by now that should't be a challenge for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_driver():\n",
    "    \"\"\"\n",
    "    Function to open the chrome webdriver.\n",
    "    \"\"\"\n",
    "    # ---\n",
    "    # add your code here\n",
    "    \n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    #chrome_options.add_argument(\"--headless\") # doesn't work yet\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    driver = webdriver.Chrome('/usr/local/bin/chromedriver', chrome_options=chrome_options)\n",
    "    \n",
    "    # ---\n",
    "    print('Chrome driver is good to go!')\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to test your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = open_driver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up a example search for both candidates on election day (Nov 8, 2016). Take a look at your URL. While the date menue is relatively complicated to navigate, changing the date through the url id straightforward, so that is what we're going to do.\n",
    "https://trends.google.com/trends/explore?hl=en&date=[START_DATE]%20[END_DATE]&geo=[REGION]&q=[SEARCH_TERMS]\n",
    "\n",
    "Note: I added `hl=en` flag to the url, otherwise the labels might not be in English and you'll have trouble matching the data.\n",
    "\n",
    "Write a function that takes a start date, end date, region, and a list of search terms as inputs and returns the url. For fancy pants: Check if `searchterms` is a list and join it using commas if necessary. Replace spaces in search terms by `%20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_url(start, end, region, searchterms):\n",
    "    \"\"\"\n",
    "    Function to construct the URL.\n",
    "    \"\"\"\n",
    "    # ---\n",
    "    # add your code here\n",
    "    \n",
    "    if isinstance(searchterms, list) == True:\n",
    "        searchterms = ','.join(map(str, searchterms)) # the easier  \",\".join(list) might not work with some symbols.\n",
    "    searchterms = searchterms.replace(' ','%20')\n",
    "    \n",
    "    url = 'https://trends.google.com/trends/explore?hl=en&date='+start+'%20'+end+'&geo='+region+'&q='+searchterms\n",
    "    \n",
    "    # ---\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchterms = [\"Donald Trump\", \"Hillary Clinton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donald Trump,Hillary Clinton'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms = ','.join(map(str, searchterms))\n",
    "search_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://trends.google.com/trends/explore?date=2016-11-08%202016-11-08&geo=US&q=Donald%20Trump,Hillary%20Clinton'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = build_url('2016-11-08','2016-11-08','US',['Donald Trump','Hillary Clinton'])\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the tricky part: Write a function that opens the url in the driver and downloads the csv file for the map. Be careful, as there are multiple download buttons!\n",
    "\n",
    "Note: Google has a nasty habit of producting an error the first time you access the url. A relatively reliable work around uses the `time.sleep()` function to wait two seconds and try again. A more sophistiated solution would check if the download button is there and reload periodically until it is (although in my experience, either you get the page on the second attempt or you don't get it anytime soon).\n",
    "\n",
    "Also: All the files will have the same name when downloaded. This can cause some problems, expecially if you start a new download while there's still a previous file in the directory. I suggest that you first remove the old file (if it exists) and that you wait at the end until your download is complete. Both can easily be achieved using an `if os.path.exists(\"path/to/your/file\"):` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_csv(url, driver):\n",
    "    \"\"\"\n",
    "    Function to download the csv file of the map.\n",
    "    \"\"\"\n",
    "    # ---\n",
    "    # add your code here\n",
    "    \n",
    "    import os\n",
    "    import time\n",
    "    print('... start download...')\n",
    "    \n",
    "    map_dl = '/Users/czuend/Downloads/geoMap.csv'\n",
    "    if os.path.exists(map_dl):\n",
    "        os.remove(map_dl)\n",
    "\n",
    "    export_map = []\n",
    "    while len(export_map) == 0:\n",
    "        print('... ... try loading the page...')\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        export_map = driver.find_elements_by_xpath('//*[@class=\"fe-multi-heat-map-generated fe-atoms-generic-container\"]')\n",
    "    \n",
    "    export_map[0].find_element_by_xpath('.//*[@title=\"CSV\"]').click()\n",
    "    \n",
    "    while not os.path.exists(map_dl):\n",
    "        time.sleep(1)\n",
    "        \n",
    "    del export_map # maybe not needed with the download_csv function. \n",
    "    \n",
    "    print('... download complete.')\n",
    "    \n",
    "    # ---\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... start download...\n",
      "... ... wait one second and try again...\n",
      "... ... wait one second and try again...\n",
      "... download complete.\n"
     ]
    }
   ],
   "source": [
    "download_csv(url, driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rename (and possibly move) the downloaded csv file. Name the file `\"map_[searchterms]_[startdate]_[enddate]_[region].csv\"`, to avoid accidentally overwriting existing files if you later explore other search specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_csv(start, end, region, searchterms):\n",
    "    \"\"\"\n",
    "    Function to rename and move files.\n",
    "    \"\"\"\n",
    "    # ---\n",
    "    # add your code here\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    if isinstance(searchterms, list) == True:\n",
    "        searchterms = ','.join(map(str, searchterms))\n",
    "    searchterms = searchterms.replace(' ','%20')\n",
    "    \n",
    "    dir = 'data'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    map_dl = '/Users/czuend/Downloads/geoMap.csv'\n",
    "    map_name = dir+'/map_'+searchterms+'_'+start+'_'+end+'_'+region+'.csv'\n",
    "\n",
    "    os.rename(map_dl, map_name)\n",
    "    \n",
    "    # ---\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename_csv('2016-11-08','2016-11-08','US',['Donald Trump','Hillary Clinton'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a list of dates to loop over. There are many ways to do this. The internet is your friend here!\n",
    "\n",
    "Note: I suggest you only scrape a month's worth of data and copy the rest from the github repo as webscraping is time consuming and not universally appreciated (e.g. by Google's system admins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dates():\n",
    "    \"\"\"\n",
    "    Function to produce a list of dates with YYYY-MM-DD from 2015-11-08 to 2016-11-08.\n",
    "    \"\"\"\n",
    "    # ---\n",
    "    # add your code here\n",
    "    \n",
    "    from datetime import date, timedelta\n",
    "    d1 = date(2016,7,2)\n",
    "    d2 = date(2016,11,8)\n",
    "    dates = [str(d1 + timedelta(days=x)) for x in range((d2-d1).days + 1)]\n",
    "    \n",
    "    # ---\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, we're ready to put everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome driver is good to go!\n",
      "Download data for:  2016-07-02\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-03\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-04\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-05\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-06\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-07\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-08\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-09\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-10\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-11\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-12\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-13\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-14\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-15\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-16\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-17\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-18\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-19\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-20\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-21\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-22\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-23\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-24\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-25\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-26\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-27\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-28\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-29\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-30\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-07-31\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-01\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-02\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-03\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-04\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-05\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-06\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-07\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-08\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-09\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-10\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-11\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-12\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-13\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-14\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-15\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-16\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-17\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-18\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-19\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-20\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-21\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-22\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-23\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-24\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-25\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-26\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-27\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-28\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-29\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-30\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-08-31\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-01\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-02\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-03\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-04\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-05\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-06\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-07\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-08\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-09\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-10\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-11\n",
      "... start download...\n",
      "... ... try loading the page...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... download complete.\n",
      "Download data for:  2016-09-12\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-13\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-14\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-15\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-16\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-17\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-18\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-19\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-20\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-21\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-22\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-23\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-24\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-25\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-26\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-27\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-28\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-29\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-09-30\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-01\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-02\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-03\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-04\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-05\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-06\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-07\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-08\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-09\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-10\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-11\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-12\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-13\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-14\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-15\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-16\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-17\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-18\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-19\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-20\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-21\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-22\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-23\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-24\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-25\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-26\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-27\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-28\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-29\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-30\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-10-31\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-01\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-02\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-03\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-04\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-05\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-06\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-07\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "Download data for:  2016-11-08\n",
      "... start download...\n",
      "... ... try loading the page...\n",
      "... download complete.\n",
      "All data downloaded.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    driver = open_driver()\n",
    "    searchterms = ['Donald Trump','Hillary Clinton']\n",
    "    region = 'US'\n",
    "    dates = get_dates()\n",
    "    for date in dates:\n",
    "        print('Download data for: ', date)\n",
    "        url = build_url(date, date, region, searchterms)\n",
    "        download_csv(url, driver)\n",
    "        rename_csv(date, date, region, searchterms)\n",
    "    driver.quit()\n",
    "    print('All data downloaded.')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d4b02f9f5bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
